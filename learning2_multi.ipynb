{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from gensim import corpora, matutils\n",
    "import pandas as pd\n",
    "import MeCab\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "\n",
    "def readCSV(file_pass, name, file_type):\n",
    "    df = pd.read_csv(file_pass+name+file_type, dtype={'label': 'str'}, encoding=\"utf-8\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def sep(body):\n",
    "    mt = MeCab.Tagger('mecabrc')\n",
    "    mt.parse(\"\")\n",
    "    node = mt.parseToNode(str(body))\n",
    "    return getNouns(node)\n",
    "\n",
    "\n",
    "def getNouns(node):\n",
    "    words = []\n",
    "    word_stack = \"\"\n",
    "    while node:\n",
    "        noun = node.feature.split(\",\")\n",
    "        word = node.surface\n",
    "        if(checkNoun(noun)):\n",
    "            word_stack += word\n",
    "        if(word_stack != \"\" and noun[0] != '名詞'):\n",
    "            if(checkNum(word_stack)):\n",
    "                words.append(word_stack)\n",
    "            word_stack = \"\"\n",
    "        node = node.next\n",
    "#     words = \" \".join(words)\n",
    "    return words\n",
    "\n",
    "\n",
    "# 名詞のみを抽出\n",
    "def checkNoun(noun):\n",
    "    if(noun[0] == '名詞'):\n",
    "        if(noun[1] != '副詞可能'):\n",
    "            if(noun[1] != '非自立'):\n",
    "                if(noun[1] != '代名詞'):\n",
    "                    if(noun[1] != '助詞類接続'):\n",
    "                        return True\n",
    "                    else:\n",
    "                        return False\n",
    "                else:\n",
    "                    return False\n",
    "            else:\n",
    "                return False\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "# 12月 1.2%などの数字関連を省く\n",
    "def checkNum(word_stack):\n",
    "    mt = MeCab.Tagger()\n",
    "    mt.parse(\"\")\n",
    "\n",
    "    node = mt.parseToNode(word_stack)\n",
    "    while node:\n",
    "        noun = node.feature.split(\",\")\n",
    "        if(noun[1] == '数'):\n",
    "            return False\n",
    "        node = node.next\n",
    "\n",
    "    return True\n",
    "\n",
    "#ラベル付け\n",
    "def ch(cat_list):\n",
    "    cats = []\n",
    "    for cat, i in zip(cat_list, range(len(cat_list))):\n",
    "        if(cat == \"1\"):\n",
    "            cats.append(i)\n",
    "    if(cats == []):\n",
    "        #すべての要素が0の時にその他のラベルである13をあてる\n",
    "        cats.append(13)\n",
    "    return np.asarray(cats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_pass = \"./\"\n",
    "#3が自作関数での分割\n",
    "file_name = \"reuters_article\"\n",
    "file_type = \".csv\"\n",
    "dict_list = []\n",
    "# print(dict_list)\n",
    "df = readCSV(file_pass, file_name, file_type)\n",
    "# print(df[\"label\"])\n",
    "body = []\n",
    "label_train = []\n",
    "# bodyに"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "body = [sep(row) for row in df[\"body\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_train = []\n",
    "for i in df[\"label\"]:\n",
    "    label_train.append(ch(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_train = MultiLabelBinarizer().fit_transform(label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(body)\n",
    "dictionary.filter_extremes(no_below=20, no_above=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = []\n",
    "# print(body)\n",
    "for b in body:\n",
    "    tmp = dictionary.doc2bow(b)\n",
    "    data_train.append(list(matutils.corpus2dense([tmp], num_terms=len(dictionary)).T[0]))\n",
    "    # print(dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(label_train)\n",
    "data_train_s, data_test_s, label_train_s, label_test_s = train_test_split(data_train, label_train, test_size=0.4)\n",
    "\n",
    "# len(data_train_s)\n",
    "\n",
    "estimator = RandomForestClassifier(n_estimators=15, random_state=0)\n",
    "estimator.fit(data_train_s, label_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.327596996245\n"
     ]
    }
   ],
   "source": [
    "print(estimator.score(data_test_s, label_test_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_pred = estimator.predict(data_train_s)\n",
    "y_test_pred = estimator.predict(data_test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.804358295208\n",
      "0.417301686446\n",
      "0.549514722816\n",
      "----------------------------------------\n",
      "0.768617255674\n",
      "0.175236479675\n",
      "0.237569703282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hurry/.pyenv/versions/anaconda3-4.0.0/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/hurry/.pyenv/versions/anaconda3-4.0.0/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(label_test_s, y_test_pred, average='micro'))\n",
    "print(recall_score(label_test_s, y_test_pred, average='micro'))\n",
    "print(f1_score(label_test_s, y_test_pred, average='micro'))\n",
    "print('-'*40)\n",
    "print(precision_score(label_test_s, y_test_pred, average='macro'))\n",
    "print(recall_score(label_test_s, y_test_pred, average='macro'))\n",
    "print(f1_score(label_test_s, y_test_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sum(data):\n",
    "    total = [0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "    for row in data:\n",
    "        for r, i in zip(row, range(len(row))):\n",
    "            total[i] += int(r)\n",
    "            \n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = sum(y_test_pred)\n",
    "true = sum(label_test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(pred)\n",
    "print(true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
